


\newcommand{\memo}[1]{{\color{red} #1 }}


%\bibliography{../../../refsaono.bib}
% \bibliography{refsaono.bib}


\clearpage

\section{Post-quantum cryptography}


We introduce which parts are replaced and should to argue by quantum peoples.

\rule{\columnwidth}{1pt}
\aono{could we move this to Sec.~\ref{sec:defense}?}

The resilience of cryptography to the computers can be explained in the following way.
The mathematical notion of security has been formulated by Shannon's discussion on the symmetric cryptography in~\cite{Sha49}.
He defined the symmetric cryptography has the perfect security (information-theoretic security) if the eavesdropper that gets ciphertext will gain no information about the plaintext.
This security notion can be described as the equivalent condition that 
uses Turing machines (TM):
for any (unlimited time and space) TM $\mathcal{G}$ that outputs a candidate of plaintext from a given ciphertext, there exists a TM $\mathcal{G}'$ with no input that satisfies
%
\begin{equation}
	\label{eqn:ITalg}
	\Pr[ \mathcal{G}(ct) = m ] = \Pr [\mathcal{G}'() = m ].
\end{equation}
%
Here, the probability is over a fixed distribution of plaintext $m$ and key $k$, and $ct = Enc(k,ct)$.
The equivalence of probabilities means that $\mathcal{G}$ needs not to use $ct$ to recover $m$, thus, $ct$ does not contain any information about $m$ intuitively.

Shannon proved that the information-theoretic security 
requires that the sender and receiver have to share 
the secret key longer than the message itself.
The source of such unwieldiness is from the tightness of perfect security that requires the eavesdropper can get no information, or it allows unlimited power to the Turing machines.
It is easy to see any public-key cryptography does not satisfy
the perfect security~\cite[Sect. 5.5.2]{GolEnc2}, 
and the followers tried to relax the notion.

\aono{the part I want to move ends here.}
\rule{\columnwidth}{1pt}

\subsection{Cryptanalyses and Base Problems}

Attacks to cryptographic schemes, i.e., revealing secret information from public information, is roughly classified into two ways: cryptanalysis to a specific scheme, and solving a base problem.
Both are studied to set suitable parameters or to check to see if the scheme is safe or not.
We mainly focus on the theoretical works
because there are very limited quantum (and its analogues) work \cite{LBC+12,War19,BPF+19} on real cryptanalyses to schemes to our best knowledge.

In theory, standard techniques to guarantee the security of cryptographic scheme 
are security reduction and hardness assumption.
The former is mathematical argument to prove that breaking scheme is harder than solving a hard problem.
Thus, with the assumption that the problem is intractable, 
the cryptographic scheme is believed to be secure.

To show it, they prove any attacker that can solve the scheme can also solve the intractable problem.
During the proof, it is considered the model of attack, i.e., how the attacker can access to the oracles.
They usually consider three types of oracles to discuss the security:  
encryption, decryption and random oracles.

The encryption oracle and decryption oracle are virtual functions which return
a result of encryption function and decryption function from its input.
With these oracles, the security against chosen plaintext attack (CPA) \cite{GM84}
and chosen ciphertext attack (CCA) \cite{NY90,DDN91} are typically 
formulated by that any attacker cannot reveal any useful information in a short time from the output of oracles even if one can choose inputs to the oracles; see textbooks \cite{Gol06book,Gol09book} for example.

Under the classical world, the attacker, usually called as ``adversary,'' is regarded as a PPTM.
Also, it is assumed to access to the oracles in a classical way,
i.e., it gets a bit sequence on each input bit sequence deterministically.
In order to argue the quantum security there are some ways to consider the quantum version of adversary and oracles.

The situation where adversary is QTM whereas the access to oracles is classical which is considered as a cryptographic model in the NISQ era.
Though there are a few number of works \cite{BHN+19} on this situation, 
we should note that the NIST post-quantum competition 
recommends to consider such situation \cite{NISTpqcriteria} for the candidates.

The other situation is both adversary and access are quantum
\cite{KM10,BZCG13,GHS16}.
It has been known \cite{AJOP20} that a quantum query has a enough power 
to break a textbook-style IND-CPA secure LWE-based encryption, that is, 
a kind of post-quantum cryptography efficiently.
One of important work is to construct secure cryptographic primitives 
against such situation.


%細山田さんレポートの短いまとめ
Also, the difference of oracle types can arise a similar security problem in the symmetric key situation.
Kaplan et al. \cite{KLLN16} modeled the ability of QTM attackers.
The Q1 (resp. Q2) model is the situation where the attacker can post classical (resp. quantum superposition) queries to the encryption oracle.
They also showed a wide class of block cipher  within a specific mode of operations can be broken in a polynomial-time under the Q2 model, 
while there are a limited number of works about attacks under the Q1 model.
As of 2020, the latter model is not realistic since it assumes a symmetric key hardware that inputs quantum superposition, but it is expected to be developed in the future.

Besides encryption/decryption oracles, 
other considered component is a random oracle \cite{BR93}.
This is also a virtual function that returns uniformly random values from every unique query.
Any asymmetric key cryptosystem must have randomness in their encrypting functions since the deterministic public-key cryptsystem is inherently not secure
in the sense of ciphertext indistinguishability \cite[Sect. 5.2.2]{Gol09book}.

In the real-world systems, cryptographic hash functions such as AES have been used to introduce the randomness.
However, it can be a barrier to carry out the rigid security proofs.
Bellare and Rogaway \cite{BR93} showed that assuming random oracle is 
useful to avoid the problem and their techniques have been used in many situations. 

In the context of post-quantum cryptography, 
another problem have been arisen.
Boneh et al. \cite{BDFL+11} showed that 
there exists a cryptographic protocol
that is secure against both classical and quantum attackers accessing to random oracle classically, but not secure against quantum attackers accessing to random oracle that returns quantum superposition.
They also noticed that a protocol based on a post-quantum intractable problem with classical security proof does not provide quantum security.
How to construct efficient and secure cryptographic protocol in the post-quantum world has been widely attracted \cite{JZM19}.

%To be extended



\subsection{Representative Candidates}

The reduction and assumption tricks allows us to discuss the security of different type of schemes by a single intractable problem.
This is the reason why peoples working on the security evaluation 
investigate how intractable the problem is against classical/quantum attacks.

This section introduces the representative post-quantum cryptographic schemes 
which can be classified into several groups with the types of basis computational problems.
As of now, they are all believed to be secure against both classical and quantum attacks, however, it has been found some subclass problems are easily solved. 


As of August 2020, there are 7 public-key encryption/Key-establishment/digital signature algorithms as the round 3 finalists of NIST post-quantum competition.
Besides, alternative 8 algorithms have been remained.
These securities rely on hard problems on lattice, coding theory, multivariate equations, isogeny, and hash function or symmetric key primitives.

The lattice-based cryptography is a generic term for cryptographic schemes 
whose security assumptions are lattice problems.
It is also widely discussed and many issues are arisen \cite{DS18} 
to its implementation in the real world.

The first lattice based public-key cryptography relied on the shortest vector problem (SVP) \cite{AD97} and practically broken by a classical computer \cite{NS98}.
Today, SVP-based schemes are considered obsolete and successor two lattice assumptions, LWE and NTRU have been used for construction.

The learning with errors (LWE) problem \cite{Regev05} is a problem to solve noisy simultaneous linear equation defined over a ring: $ \langle \bm{a}_i , \bm{s}_i\rangle  \approx b_i $ for $i=1,\ldots$ where $\bm{a}_i$'s and $\bm{s}_i$'s are vectors.
The problem harder than SVP with suitable parameter settings \cite{BLPRS13} and 
believed to be hard against quantum computers \cite{Regev05}.
One drawback of standard LWE-based schemes is key size to store/send elements $\{ (\bm{a}_i,b_i) \} $ used as a public key.

Schemes based on Ring-LWE problem \cite{LPR13} and NTRU problem \cite{HPS98,SS11} are considered to avoid it.
They compress the public keys by using mathematical structure, but however, 
it has been still open whether it is secure against classical/quantum computers.
In fact, some subclass of the problems is solved efficiently \cite{Duc17}.
The main open problem is to investigate structures that satisfies both efficiency and quantum resilience.

The parameter setting on lattice-based cryptsystems 
is mainly from the hardness estimation of SVP besides vulnerabilities from special structures.
Following the classical setting, the hardness estimations in quantum setting
are due to the lattice vector enumeration \cite{Kannan83,GNR10} and sieve algorithm \cite{AKS01}.
The former \cite{ANS18} is an adaptation of quantum tree search \cite{Mon18} using quantum walk, and the latter \cite{LMP15,KMP+19} is 
the near-collision searching by an adaptation of Grover search.

The code-based cryptography is the class of cryptographic schemes 
based on the hardness of syndrome decoding of linear codes, which is one of NP-hard problem \cite{BMvT78,Has01}.
It has a long history since McEliece \cite{McE78}.
public keys respectively;
here, $G'$ is computed from $G$ and how to compute it is also secret.
For a plaintext $m$ and its code $mG'$, ciphertext is $c=mG'+e$ where $e$ is an error bits which is randomly generated by the sender.
Similar to the lattice-based cryptography, 
the code based cryptography has the key size drawbacks
and consider several structure in generator matrices.

A fundamental idea is to use the generator matrix $G$ and $G'$ as the secret and 
As of now, although the syndrome decoding is used many situations in communication, no polynomial-time classical or quantum algorithm to solve it in general setting.
However, quantum speed up from the classical using Grover and quantum walk have been discovered \cite{KT17}.

Multivariate cryptography is the generic class of cryptographic primitives whose security is based on the problem to solve multivariate algebraic equations over a finite field.
The modern style multivariate cryptosystem is proposed by Matsumoto-Imai \cite{MI88} and a practical polynomial attack \cite{Pat95} has been discovered
and propose a countermeasure \cite{Pat96}.
As of now, multivariate cryptgraphic primitives are mainly used to construct digital signatures \cite{NISTpqround3}.
The parameters are mainly from the estimation of classical attacks \cite{}
while a few works on quantum analyses \cite{FHK+17,BY18} based on the Grover search.

Isogeny-based cryptography is a class of cryptosystem whose security base is computational problems on supersingular elliptic curves.
Jao and De Feo introduced a post-quantum key-exchange scheme SIDH \cite{JF11}
and it was extended to a public key scheme SIKE \cite{SIKEweb} which is remained as an alternative candidate in round 3 \cite{NISTpqround3}.
Here, SIKE and SIDH stand for supersingular isogeny key encapsulation
and supersingular isogeny Diffie–Hellman, respectively.

Since the Diffie-Hellman key exchange (DHKX) protocol can work over many group structures, it has been a long-standing problem to search a structure that has both efficiency and security.
The SIDH protocol is an analogue of DHKX that utilizes 
the walks in a supersingular isogeny graph \cite{JF11}.
The shared element is computed from an invariant of a supersingular elliptic curve instead of group elements,
and security relies on the SIDH problem.
Similar to the situation of standard Diffie-Hellman,
this is a mathematical formulation of the problem that computes 
shared data from the public elements on SIDH protocol;
for the detailed mathematical arguments, see \cite{Feo17,GV18}.

The hardness of SIDH depends on the characteristic $p$ of field to define the curves.
The best known algorithms achieves the classical time $O(p^{1/4})$ (also requires the same magnitude of space) by meet-in-the-middle approach \cite{GPST16,ACC+19} and quantum time $O(p^{1/6})$ via Tani's claw finding \cite{Tani09}.
Thus, it has been believed that the problem is intractable against quantum computers.

Hash-based cryptography is the set of cryptogrpahic primitives whose securities are from the security of hash functions like SHA-3 \cite{SHA3}.
Despite of its long history \cite{Lam79}, 
as of 2020, applications are only digital signature schemes using a tree structure \cite{BHH+15}.
Since the security completely relies on the property of base hash function, it is widely believed to be secure against quantum computers.

********** Aono part end ***********


%-----------------------------------------------------Here end of my section



% =======


% =======
% \clearpage 

% \section{Post-quantum cryptography}

\subsection{rdv's notes}

\comment{Jon Dowling (RIP)'s opinions here were strong.  He believed that
  post-quantum crypto is fundamentally impossible, that all of the
  interesting asymmetric problems useful for authentication and key
  generation will ultimately fall to quantum algorithms.}

\comment{Aono: lattice crypto is very attractive because a) it reduces to
shortest vector or other problems, and b) implementation is easy,
basically a matrix times a vector~\cite{regev09:jacm}.}

\comment{learning w/ errors As + e = t mod q
candidate for post-quantum crypto}

\comment{(n.b.: cocori created a ipynb, but misunderstood the size of the
matrix necessary)}


Post-quantum cryptography is the attempt to find a public key
cryptosystem that is resistant to quantum computing, Shor's algorithm
in particular.

There is enough interest in this that the Wikipedia pages are
essentially extensive catalogs:
\url{https://en.wikipedia.org/wiki/Post-quantum_cryptography}
\url{https://en.wikipedia.org/wiki/Post-Quantum_Cryptography_Standardization}

An official-looking site:
\url{https://csrc.nist.gov/projects/post-quantum-cryptography/post-quantum-cryptography-standardization}

One recent blog posting of some use:
\url{https://blog.trailofbits.com/2018/10/22/a-guide-to-post-quantum-cryptography/}

A very recent blog posting on teaching crypto in the post-quantum
crypto age:
\url{https://news.ncsu.edu/2019/06/teaching-next-generation-cryptosystems/}
which builds on a conference presentation on the course they created:
\url{https://dl.acm.org/citation.cfm?id=3317994}
which goes into a lot of detail on crypto hardware.

A survey from a decade ago:
\url{https://www.nist.gov/publications/quantum-resistant-public-key-cryptography-survey?pub_id=901595}

Also in 2009, there was a book, which I'm sure is almost entirely
outdated by now:
\url{https://www.springer.com/jp/book/9783540887010}

Transition doc from IETF, still in draft:
\url{https://datatracker.ietf.org/doc/draft-hoffman-c2pq/}

\url{https://eprint.iacr.org/2017/847.pdf}

\url{https://arstechnica.com/gadgets/2020/07/ibm-completes-successful-field-trials-on-fully-homomorphic-encryption/}

\subsection{Notes \& References}

To be filled in eventually, mostly by moving the existing parts of
this section into this subsection!



